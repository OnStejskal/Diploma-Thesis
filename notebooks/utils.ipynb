{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from os.path import join\n",
    "\n",
    "def create_folder_structure_for_segmentation(images_folder, labels_folder, dir_path, num_train_images = 76, num_val_images = 25):\n",
    "    # Get list of filenames in both folders\n",
    "    image_files = os.listdir(images_folder)\n",
    "    label_files = os.listdir(labels_folder)\n",
    "\n",
    "    # Sort the filenames to ensure correspondence\n",
    "    image_files.sort()\n",
    "    label_files.sort()\n",
    "\n",
    "    # Calculate the number of files for training\n",
    "    # num_train = int(train_ratio * len(image_files))\n",
    "    # num_val = int((train_ratio+val_ratio) * len(image_files))\n",
    "\n",
    "    # Create train and validation folders if not exists\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "    os.makedirs(join(dir_path, \"train\"))\n",
    "    os.makedirs(join(dir_path, \"val\"))\n",
    "    os.makedirs(join(dir_path, \"test\"))\n",
    "\n",
    "    train_images_path =join(dir_path, \"train\", \"images\")\n",
    "    val_images_path = join(dir_path, \"val\",\"images\")\n",
    "    train_segmentaion_path = join(dir_path, \"train\", \"segmentations\")\n",
    "    val_segmentations_path = join(dir_path, \"val\", \"segmentations\")\n",
    "    test_images_path =join(dir_path, \"test\", \"images\")\n",
    "    test_segmentations_path =join(dir_path, \"test\", \"segmentations\")\n",
    "\n",
    "\n",
    "    os.makedirs(train_images_path)\n",
    "    os.makedirs(val_images_path)\n",
    "    os.makedirs(train_segmentaion_path)\n",
    "    os.makedirs(val_segmentations_path)\n",
    "    os.makedirs(test_images_path)\n",
    "    os.makedirs(test_segmentations_path)\n",
    "\n",
    "    # Copy images to train folder\n",
    "    for image_file in image_files[:num_train_images]:\n",
    "        src_image = os.path.join(images_folder, image_file)\n",
    "        dst_image = os.path.join(train_images_path, image_file)\n",
    "\n",
    "        shutil.copy(src_image, dst_image)\n",
    "\n",
    "    # Copy labels to train folder\n",
    "    for label_file in label_files[:num_train_images]:\n",
    "        src_label = os.path.join(labels_folder, label_file)\n",
    "        dst_label = os.path.join(train_segmentaion_path, label_file)\n",
    "        shutil.copy(src_label, dst_label)\n",
    "\n",
    "    # Copy remaining images to validation folder\n",
    "    for image_file in image_files[num_train_images:num_train_images + num_val_images]:\n",
    "        src_image = os.path.join(images_folder, image_file)\n",
    "        dst_image = os.path.join(val_images_path, image_file)\n",
    "        shutil.copy(src_image, dst_image)\n",
    "\n",
    "    # Copy remaining labels to validation folder\n",
    "    for label_file in label_files[num_train_images:num_train_images + num_val_images]:\n",
    "        src_label = os.path.join(labels_folder, label_file)\n",
    "        dst_label = os.path.join(val_segmentations_path, label_file)\n",
    "        shutil.copy(src_label, dst_label)\n",
    "\n",
    "\n",
    "    # Copy remaining images to validation folder\n",
    "    for image_file in image_files[num_train_images + num_val_images:]:\n",
    "        src_image = os.path.join(images_folder, image_file)\n",
    "        dst_image = os.path.join(test_images_path, image_file)\n",
    "        shutil.copy(src_image, dst_image)\n",
    "\n",
    "    # Copy remaining labels to validation folder\n",
    "    for label_file in label_files[num_train_images + num_val_images:]:\n",
    "        src_label = os.path.join(labels_folder, label_file)\n",
    "        dst_label = os.path.join(test_segmentations_path, label_file)\n",
    "        shutil.copy(src_label, dst_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folder_structure_for_segmentation(join(\"data\",\"cropped_segmentation_data\", \"data\",\"trans\"), join(\"data\",\"cropped_segmentation_data\", \"references\",\"trans\"), join(\"segmentation\", \"data\", \"cropped_fully_annotated\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Create a ResNet-18 model\n",
    "resnet18 = models.resnet18()\n",
    "\n",
    "# Print the layers of the ResNet-18 model\n",
    "for name, module in resnet18.named_children():\n",
    "    print(f\"{name}: {module}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Create a ResNet-18 model\n",
    "resnet18 = models.resnet34()\n",
    "\n",
    "# Print the layers of the ResNet-18 model\n",
    "for name, module in resnet18.named_children():\n",
    "    print(f\"{name}: {module}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "path = \"C://Users//ondra//school//Diplomka//diploma-thesis//data//new_segmentation_data//data//trans//p_201501061017320170VAS.png\"\n",
    "img = Image.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rgb_image = Image.open(path)\n",
    "grayscale_image = rgb_image.convert('L')\n",
    "\n",
    "# Plot the RGB image\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('RGB Image')\n",
    "plt.imshow(rgb_image)\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot the grayscale image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Grayscale Image')\n",
    "plt.imshow(grayscale_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image_path = path\n",
    "rgb_image = Image.open(image_path)\n",
    "grayscale_image = rgb_image.convert('L')\n",
    "\n",
    "# Get the size of the image\n",
    "width, height = rgb_image.size\n",
    "\n",
    "# Calculate the coordinates for the 3x3 pixel region in the middle\n",
    "x_center = width // 2\n",
    "y_center = height // 2\n",
    "x_start = x_center - 1\n",
    "x_end = x_center + 2\n",
    "y_start = y_center - 1\n",
    "y_end = y_center + 2\n",
    "\n",
    "# Extract the 3x3 pixel region from both images\n",
    "rgb_pixels = np.array(rgb_image)\n",
    "grayscale_pixels = np.array(grayscale_image)\n",
    "\n",
    "rgb_patch = rgb_pixels[y_start:y_end + 1, x_start:x_end + 1, :]\n",
    "grayscale_patch = grayscale_pixels[y_start:y_end + 1, x_start:x_end + 1]\n",
    "\n",
    "# Print the RGB pixel values\n",
    "print(\"RGB Pixel Values:\")\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        print(f\"RGB ({x_start + j}, {y_start + i}): {rgb_patch[i, j]}\")\n",
    "\n",
    "# Print the grayscale pixel values\n",
    "print(\"\\nGrayscale Pixel Values:\")\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        print(f\"Grayscale ({x_start + j}, {y_start + i}): {grayscale_patch[i, j]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def w_nll_loss(prediction, label, n_classes = False):\n",
    "    # eps = 0.001\n",
    "    weights = []\n",
    "    total_pixels = label.numel()\n",
    "    if not n_classes:\n",
    "        n_classes = prediction.shape[1]\n",
    "    for i in range(n_classes):\n",
    "        # BY PAPER IN CODE DIFFERENT\n",
    "        weights.append(1-(torch.sum(label == i).item()/total_pixels))\n",
    "    print(\"w \",weights)\n",
    "    # weights = torch.ones(n_classes)\n",
    "    # one_hot_encoded_label = one_hot(label, n_classes)\n",
    "    weighted_cross_entropy = F.nll_loss(torch.log(prediction), label, weight=torch.tensor(weights).to(prediction.device))\n",
    "    return weighted_cross_entropy\n",
    "\n",
    "def weighted_cross_entropy_loss(outputs, targets, num_classes = 4):\n",
    "    \"\"\"\n",
    "    Custom cross-entropy loss for already softmaxed outputs, \n",
    "    ignoring targets with a label of zero, and adding class weights.\n",
    "    \n",
    "    :param outputs: Softmax probabilities of each class at each pixel, \n",
    "                    shape [batch_size, num_classes, height, width]\n",
    "    :param targets: Ground truth labels, shape [batch_size, height, width]\n",
    "    :param num_classes: Number of classes\n",
    "    :return: Loss value\n",
    "    \"\"\"\n",
    "    # Ensure the outputs are valid probabilities\n",
    "    outputs = torch.clamp(outputs, min=1e-7, max=1 - 1e-7)  # Prevent log(0)\n",
    "    \n",
    "    # Create a mask for non-zero target labels\n",
    "    # mask = (targets != 0).float()\n",
    "\n",
    "    # Calculate class weights\n",
    "    class_weights = []\n",
    "    total_pixels = float(targets.numel())  # Total number of labeled pixels\n",
    "    for c in range(0, num_classes):  # Start from 1 to ignore class 0\n",
    "        class_pixels = float((targets == c).sum())\n",
    "        class_weight = 1 - (class_pixels / total_pixels)\n",
    "        class_weights.append(class_weight)\n",
    "    class_weights = torch.tensor(class_weights).to(outputs.device)\n",
    "    # class_weights = torch.ones(num_classes)\n",
    "    # Gather the probabilities for the correct classes and apply class weights\n",
    "    gathered_probs = outputs.gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "    log_probs = torch.log(gathered_probs)\n",
    "    print(\"w \",class_weights)\n",
    "    weighted_log_probs = log_probs * class_weights[targets]  # Adjust class index for zero-indexing\n",
    "    # Apply mask and compute the loss\n",
    "    loss = - (weighted_log_probs).sum() / total_pixels\n",
    "\n",
    "    return loss\n",
    "\n",
    "def weighted_partial_cross_entropy_loss(outputs, targets, num_classes = 4):\n",
    "    \"\"\"\n",
    "    Custom cross-entropy loss for already softmaxed outputs, \n",
    "    ignoring targets with a label of zero, and adding class weights.\n",
    "    \n",
    "    :param outputs: Softmax probabilities of each class at each pixel, \n",
    "                    shape [batch_size, num_classes, height, width]\n",
    "    :param targets: Ground truth labels, shape [batch_size, height, width]\n",
    "    :param num_classes: Number of classes\n",
    "    :return: Loss value\n",
    "    \"\"\"\n",
    "    # Ensure the outputs are valid probabilities\n",
    "    outputs = torch.clamp(outputs, min=1e-7, max=1 - 1e-7)  # Prevent log(0)\n",
    "    \n",
    "    # Create a mask for non-zero target labels\n",
    "    mask = (targets != 0).float()\n",
    "\n",
    "    # Calculate class weights\n",
    "    class_weights = [0]\n",
    "    total_pixels = float(mask.sum())  # Total number of labeled pixels\n",
    "    for c in range(1, num_classes):  # Start from 1 to ignore class 0\n",
    "        class_pixels = float((targets == c).sum())\n",
    "        class_weight = 1 - (class_pixels / total_pixels)\n",
    "        class_weights.append(class_weight)\n",
    "    class_weights = torch.tensor(class_weights).to(outputs.device)\n",
    "\n",
    "    # Gather the probabilities for the correct classes and apply class weights\n",
    "    gathered_probs = outputs.gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "    print(gathered_probs.shape)\n",
    "    print(gathered_probs)\n",
    "    print(class_weights.shape)\n",
    "    log_probs = torch.log(gathered_probs)\n",
    "    print(\"before w\")\n",
    "    print(log_probs)\n",
    "    print(\"w\")\n",
    "    print(class_weights)\n",
    "    weighted_log_probs = log_probs * class_weights[targets]  # Adjust class index for zero-indexing\n",
    "    print(\"afyet w\")\n",
    "    print(weighted_log_probs)\n",
    "    # Apply mask and compute the loss\n",
    "    loss = - (weighted_log_probs * mask).sum() / mask.sum()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def custom_cross_entropy_loss_without_softmax(outputs, targets):\n",
    "    \"\"\"\n",
    "    Custom cross-entropy loss for already softmaxed outputs, \n",
    "    ignoring targets with a label of zero.\n",
    "    \n",
    "    :param outputs: Softmax probabilities of each class at each pixel, \n",
    "                    shape [batch_size, num_classes, height, width]\n",
    "    :param targets: Ground truth labels, shape [batch_size, height, width]\n",
    "    :return: Loss value\n",
    "    \"\"\"\n",
    "    # Ensure the outputs are softmax probabilities\n",
    "    outputs = torch.clamp(outputs, min=1e-7, max=1 - 1e-7)  # Prevent log(0)\n",
    "    \n",
    "    # Create a mask for non-zero target labels\n",
    "    mask = (targets != 0).float()\n",
    "\n",
    "    # Gather the probabilities for the correct classes\n",
    "    gathered_probs = outputs.gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "    # Compute the log of probabilities\n",
    "    log_probs = torch.log(gathered_probs)\n",
    "\n",
    "    # Apply mask and compute the loss\n",
    "    loss = - (log_probs * mask).sum() / mask.sum()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def custom_nll_loss(outputs, targets):\n",
    "    mask = targets != 0\n",
    "    print(\"mask:\",mask)\n",
    "    outputs = outputs[torch.arange(outputs.shape[0]).unsqueeze(1), targets] * mask\n",
    "    loss = -outputs.sum() / mask.sum()\n",
    "    return loss\n",
    "\n",
    "# Mock data for testing\n",
    "# Let's assume we have a batch size of 1, 3 classes, and a 2x2 image\n",
    "batch_size, num_classes, height, width = 1, 4, 2, 2\n",
    "\n",
    "# Create random logits and apply log_softmax to simulate model outputs\n",
    "logits = torch.randn(batch_size, num_classes, height, width)\n",
    "outputs = F.softmax(logits)\n",
    "# Create target labels (ground truth)\n",
    "# Let's have one unlabeled pixel (with label 0) and others with labels\n",
    "targets = torch.tensor([[[1, 1], [2, 1]]])\n",
    "\n",
    "# Print inputs\n",
    "print(\"Model Outputs (Log Probabilities):\")\n",
    "print(outputs)\n",
    "print(\"\\nTarget Labels:\")\n",
    "print(targets)\n",
    "\n",
    "# # Compute and print the custom loss\n",
    "# loss = custom_nll_loss(outputs, targets)\n",
    "# print(\"\\nComputed Loss:\")\n",
    "# print(loss)\n",
    "\n",
    "\n",
    "# loss = F.cross_entropy(logits, targets)\n",
    "# print(\"\\nComputed Loss:\")\n",
    "# print(loss)\n",
    "\n",
    "# loss = weighted_partial_cross_entropy_loss(outputs, targets)\n",
    "# print(\"\\nComputed Loss:\")\n",
    "# print(loss)\n",
    "\n",
    "loss = weighted_cross_entropy_loss(outputs, targets)\n",
    "print(\"\\nComputed Loss:\")\n",
    "print(loss)\n",
    "\n",
    "loss = w_nll_loss(outputs, targets)\n",
    "print(\"\\nComputed Loss:\")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "\n",
    "def weighted_cross_entropy_loss(outputs, targets, class_weights):\n",
    "    \"\"\"\n",
    "    Weighted cross entropy loss for already softmaxed outputs.\n",
    "\n",
    "    :param outputs: Softmax probabilities from the neural network,\n",
    "                    shape [batch_size, num_classes, height, width].\n",
    "    :param targets: Ground truth labels, shape [batch_size, height, width].\n",
    "    :param class_weights: Tensor of shape [num_classes] with class weights.\n",
    "    :return: Weighted cross entropy loss.\n",
    "    \"\"\"\n",
    "    # Ensure class_weights is a tensor and move to the same device as outputs\n",
    "    class_weights = torch.tensor(class_weights, dtype=outputs.dtype).to(outputs.device)\n",
    "\n",
    "    # Reshape targets to use for gather\n",
    "    targets = targets.unsqueeze(1)  # shape becomes [batch_size, 1, height, width]\n",
    "\n",
    "    # Gather the probabilities of the true classes\n",
    "    true_class_probs = torch.gather(outputs, 1, targets).squeeze(1)\n",
    "\n",
    "    # Apply weights to the gathered probabilities\n",
    "    weights = class_weights[targets].squeeze(1)  # shape becomes [batch_size, height, width]\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = -torch.log(true_class_probs + 1e-6) * weights  # Adding epsilon for numerical stability\n",
    "    return loss.mean()\n",
    "\n",
    "# # Example usage\n",
    "# batch_size, num_classes, height, width = 1, 3, 4, 4\n",
    "# outputs = torch.softmax(torch.randn(batch_size, num_classes, height, width), dim=1)  # Example softmaxed outputs\n",
    "# targets = torch.randint(0, num_classes, (batch_size, height, width))  # Example targets\n",
    "# class_weights = torch.tensor([1.0, 2.0, 0.5])  # Example class weights\n",
    "\n",
    "# loss = weighted_cross_entropy_loss(outputs, targets, class_weights)\n",
    "# print(loss)\n",
    "\n",
    "\n",
    "def weighted_cross_entropy_for_softmaxed_output(outputs, targets, class_weights):\n",
    "    \"\"\"\n",
    "    Weighted cross entropy loss for already softmaxed outputs.\n",
    "\n",
    "    :param outputs: Softmax probabilities from the neural network,\n",
    "                    shape [batch_size, num_classes, height, width].\n",
    "    :param targets: Ground truth labels, shape [batch_size, height, width].\n",
    "    :param class_weights: Tensor of shape [num_classes] with class weights.\n",
    "    :return: Weighted cross entropy loss.\n",
    "    \"\"\"\n",
    "    # Convert softmax outputs to log probabilities\n",
    "    log_probs = torch.log(outputs + 1e-6)  # Adding epsilon for numerical stability\n",
    "\n",
    "    # Compute the weighted NLL loss\n",
    "    loss = F.nll_loss(log_probs, targets, weight=class_weights, reduction='mean')\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Example usage\n",
    "batch_size, num_classes, height, width = 1, 3, 2, 2\n",
    "o = torch.randn(batch_size, num_classes, height, width)\n",
    "outputs = torch.softmax(o, dim=1)  # Example softmaxed outputs\n",
    "targets = torch.randint(0, num_classes, (batch_size, height, width))  # Example targets\n",
    "\n",
    "class_weights = torch.tensor([2.0, 1.0, 1.0])  # Example class weights\n",
    "loss = weighted_cross_entropy_for_softmaxed_output(outputs, targets, class_weights)\n",
    "print(loss)\n",
    "\n",
    "loss = weighted_cross_entropy_loss(outputs, targets, class_weights)\n",
    "print(loss)\n",
    "\n",
    "loss = F.cross_entropy(o, targets, class_weights)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def wce_already_sofmaxed(outputs, targets):\n",
    "    \"\"\"\n",
    "    Weighted cross entropy loss for already softmaxed outputs.\n",
    "\n",
    "    :param outputs: Softmax probabilities from the neural network,\n",
    "                    shape [batch_size, num_classes, height, width].\n",
    "    :param targets: Ground truth labels, shape [batch_size, height, width].\n",
    "    :param class_weights: Tensor of shape [num_classes] with class weights.\n",
    "    :return: Weighted cross entropy loss.\n",
    "    \"\"\"\n",
    "    # Convert softmax outputs to log probabilities\n",
    "    class_weights = []\n",
    "    total_pixels = float(targets.numel())  # Total number of labeled pixels\n",
    "    for c in range(0, num_classes):  # Start from 1 to ignore class 0\n",
    "        class_pixels = float((targets == c).sum())\n",
    "        class_weight = 1 - (class_pixels / total_pixels)\n",
    "        class_weights.append(class_weight)\n",
    "    class_weights = torch.tensor(class_weights).to(outputs.device)\n",
    "    log_probs = torch.log(outputs + 1e-6)  # Adding epsilon for numerical stability\n",
    "    loss = F.nll_loss(log_probs, targets, weight=class_weights, reduction='mean')\n",
    "\n",
    "    return loss\n",
    "\n",
    "# def weighted_cross_entropy_loss(outputs, targets, class_weights):\n",
    "#     \"\"\"\n",
    "#     Weighted cross entropy loss for already softmaxed outputs, \n",
    "#     computed only for annotated pixels.\n",
    "\n",
    "#     :param outputs: Softmax probabilities from the neural network,\n",
    "#                     shape [batch_size, num_classes, height, width].\n",
    "#     :param targets: Ground truth labels, shape [batch_size, height, width].\n",
    "#                     Annotated pixels are non-zero.\n",
    "#     :param class_weights: Tensor of shape [num_classes] with class weights.\n",
    "#     :return: Weighted cross entropy loss.\n",
    "#     \"\"\"\n",
    "#     # Ensure class_weights is a tensor and move to the same device as outputs\n",
    "#     class_weights = torch.tensor(class_weights, dtype=outputs.dtype).to(outputs.device)\n",
    "\n",
    "#     # Create a mask for annotated pixels (non-zero in targets)\n",
    "#     mask = targets != 0\n",
    "\n",
    "#     # Reshape targets to use for gather, and apply the mask\n",
    "#     targets_masked = targets.unsqueeze(1) * mask.unsqueeze(1)\n",
    "\n",
    "#     # Gather the probabilities of the true classes for annotated pixels\n",
    "#     true_class_probs = torch.gather(outputs, 1, targets_masked).squeeze(1)\n",
    "\n",
    "#     # Apply class weights\n",
    "#     weights = class_weights[targets] * mask\n",
    "\n",
    "#     # Compute the loss, ignore unannotated pixels by masking\n",
    "#     loss = -torch.log(true_class_probs + 1e-6) * weights  # Adding epsilon for numerical stability\n",
    "#     return loss[mask].mean()  # Average over only the annotated pixels\n",
    "\n",
    "def pwce_already_sofmaxed(outputs, targets):\n",
    "    \"\"\"\n",
    "    Partial Weighted NLL loss for softmaxed outputs, computed only on annotated pixels.\n",
    "\n",
    "    :param outputs: Softmax probabilities from the neural network,\n",
    "                    shape [batch_size, num_classes, height, width].\n",
    "    :param targets: Ground truth labels, shape [batch_size, height, width].\n",
    "                    Annotated pixels are non-zero.\n",
    "    :param class_weights: Tensor of shape [num_classes] with class weights.\n",
    "    :return: Weighted NLL loss.\n",
    "    \"\"\"\n",
    "    mask = targets != 0\n",
    "\n",
    "    # Convert softmax outputs to log probabilities\n",
    "    class_weights = [0]\n",
    "    total_pixels = float(mask.sum())  # Total number of labeled pixels\n",
    "    for c in range(1, num_classes):  # Start from 1 to ignore class 0\n",
    "        class_pixels = float((targets == c).sum())\n",
    "        class_weight = 1 - (class_pixels / total_pixels)\n",
    "        class_weights.append(class_weight)\n",
    "    class_weights = torch.tensor(class_weights).to(outputs.device)\n",
    "\n",
    "    log_probs = torch.log(outputs + 1e-6)  # Add epsilon for numerical stability\n",
    "\n",
    "    # Create a mask for annotated pixels (non-zero in targets)\n",
    "    mask = targets != 0\n",
    "\n",
    "    # Apply the mask to targets\n",
    "    masked_targets = targets * mask\n",
    "\n",
    "\n",
    "    # print(log_probs.shape)\n",
    "    # print(masked_targets.shape)\n",
    "    # Compute the NLL loss\n",
    "    loss = F.nll_loss(log_probs, masked_targets, weight=class_weights, reduction='mean')\n",
    "    return loss\n",
    "    # print(loss)\n",
    "    # Apply the mask to the loss and compute the mean loss over annotated pixels\n",
    "    # loss = loss * mask\n",
    "    # return loss[mask].mean()\n",
    "\n",
    "\n",
    "def pwce_already_sofmaxed2(outputs, targets):\n",
    "    \"\"\"\n",
    "    Partial Weighted NLL loss for softmaxed outputs, computed only on annotated pixels.\n",
    "\n",
    "    :param outputs: Softmax probabilities from the neural network,\n",
    "                    shape [batch_size, num_classes, height, width].\n",
    "    :param targets: Ground truth labels, shape [batch_size, height, width].\n",
    "                    Annotated pixels are non-zero.\n",
    "    :param class_weights: Tensor of shape [num_classes] with class weights.\n",
    "    :return: Weighted NLL loss.\n",
    "    \"\"\"\n",
    "    mask = targets != 0\n",
    "\n",
    "    class_weights = [0]\n",
    "    total_pixels = float(mask.sum())  # Total number of labeled pixels\n",
    "    for c in range(1, num_classes):  # Start from 1 to ignore class 0\n",
    "        class_pixels = float((targets == c).sum())\n",
    "        class_weight = 1 - (class_pixels / total_pixels)\n",
    "        class_weights.append(class_weight)\n",
    "    class_weights = torch.tensor(class_weights).to(outputs.device)\n",
    "\n",
    "    log_probs = torch.log(outputs + 1e-6)  # Add epsilon for numerical stability\n",
    "\n",
    "    loss = F.nll_loss(log_probs, targets, weight=class_weights, reduction='mean')\n",
    "    return loss\n",
    "    # print(loss)\n",
    "    # Apply the mask to the loss and compute the mean loss over annotated pixels\n",
    "    # loss = loss * mask\n",
    "    # return loss[mask].mean()\n",
    "\n",
    "\n",
    "\n",
    "# def weighted_cross_entropy_loss_fuull(outputs, targets, class_weights):\n",
    "#     \"\"\"\n",
    "#     Weighted cross entropy loss for already softmaxed outputs.\n",
    "\n",
    "#     :param outputs: Softmax probabilities from the neural network,\n",
    "#                     shape [batch_size, num_classes, height, width].\n",
    "#     :param targets: Ground truth labels, shape [batch_size, height, width].\n",
    "#     :param class_weights: Tensor of shape [num_classes] with class weights.\n",
    "#     :return: Weighted cross entropy loss.\n",
    "#     \"\"\"\n",
    "#     # Ensure class_weights is a tensor and move to the same device as outputs\n",
    "#     class_weights = torch.tensor(class_weights, dtype=outputs.dtype).to(outputs.device)\n",
    "\n",
    "#     # Reshape targets to use for gather\n",
    "#     targets = targets.unsqueeze(1)  # shape becomes [batch_size, 1, height, width]\n",
    "\n",
    "#     # Gather the probabilities of the true classes\n",
    "#     true_class_probs = torch.gather(outputs, 1, targets).squeeze(1)\n",
    "\n",
    "#     # Apply weights to the gathered probabilities\n",
    "#     weights = class_weights[targets].squeeze(1)  # shape becomes [batch_size, height, width]\n",
    "\n",
    "#     # Compute the loss\n",
    "#     loss = -torch.log(true_class_probs + 1e-6) * weights  # Adding epsilon for numerical stability\n",
    "#     print(loss)\n",
    "#     return loss.mean()\n",
    "def w_nll_loss(prediction, label, n_classes = False):\n",
    "    # eps = 0.001\n",
    "    weights = []\n",
    "    total_pixels = label.numel()\n",
    "    if not n_classes:\n",
    "        n_classes = prediction.shape[1]\n",
    "    for i in range(n_classes):\n",
    "        # BY PAPER IN CODE DIFFERENT\n",
    "        weights.append(1-(torch.sum(label == i).item()/total_pixels))\n",
    "    \n",
    "    # one_hot_encoded_label = one_hot(label, n_classes)\n",
    "    weighted_cross_entropy = F.nll_loss(torch.log(prediction), label, weight=torch.tensor(weights).to(prediction.device))\n",
    "    return weighted_cross_entropy\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "batch_size, num_classes, height, width = 1, 4, 100, 100\n",
    "o  = torch.randn(batch_size, num_classes, height, width)\n",
    "outputs = torch.softmax(o, dim=1)  # Example softmaxed outputs\n",
    "targets = torch.randint(0, num_classes, (batch_size, height, width))  # Example targets with some zeros\n",
    "# targets = torch.tensor([[[0, 1], [2, 2]]])\n",
    "\n",
    "\n",
    "loss = wce_already_sofmaxed(outputs, targets)\n",
    "print(loss)\n",
    "loss = pwce_already_sofmaxed(outputs, targets)\n",
    "print(loss)\n",
    "loss = pwce_already_sofmaxed2(outputs, targets)\n",
    "print(loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def dice_loss(predictions, labels, include_background = False, apply_softamax = False):\n",
    "    \"\"\"compute dice loss as a mean dice score across all classes\n",
    "\n",
    "    Args:\n",
    "        predictions (tensor(batch, num_clases, height, width)): predictions from segmentation models 0 to 1 probabilites for class\n",
    "        labels (tensor(batch, height, width)): labels for each pixel, values = 0...number of classes - 1\n",
    "        include_background (bool, optional): if True include background class. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tensor[1]: loss\n",
    "    \"\"\"\n",
    "\n",
    "    n_classes = predictions.shape[1]\n",
    "    labels_oh = torch.nn.functional.one_hot(labels, num_classes=n_classes).permute((0,3,1,2))\n",
    "    if apply_softamax:\n",
    "        predictions = torch.nn.functional.softmax(predictions, dim = 1)\n",
    "\n",
    "    # if not soft:\n",
    "    #     predictions = torch.argmax(predictions, dim=1)\n",
    "    #     predictions = nn.functional.one_hot(predictions, num_classes = n_classes).permute((0,3,1,2))\n",
    "\n",
    "    if not include_background:\n",
    "        predictions = predictions[:,1:, :, :]\n",
    "        labels_oh = labels_oh[:,1:,:,:]\n",
    "\n",
    "    intersection = torch.sum(predictions * labels_oh, dim=(1,2,3))\n",
    "    union = torch.sum(predictions, dim=(1,2,3)) + torch.sum(labels_oh, dim=(1,2,3))\n",
    "    dice_score = (2.0 * intersection) / (union)  # Adding a small epsilon to avoid division by zero\n",
    "    return 1 - torch.mean(dice_score, dim=0)\n",
    "\n",
    "# Define the DiceLoss class as previously described\n",
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, smooth=1e-5):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        predictions = torch.sigmoid(predictions)\n",
    "        predictions = predictions.contiguous().view(predictions.shape[0], predictions.shape[1], -1)\n",
    "        targets = targets.contiguous().view(targets.shape[0], targets.shape[1], -1)\n",
    "\n",
    "        intersection = (predictions * targets).sum(2)\n",
    "        denominator = predictions.sum(2) + targets.sum(2)\n",
    "\n",
    "        dice = (2. * intersection + self.smooth) / (denominator + self.smooth)\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "# Simulate predictions and targets\n",
    "batch_size, num_classes, height, width = 4, 3, 256, 256  # Example dimensions\n",
    "\n",
    "# Randomly generated predictions and targets for testing\n",
    "predictions = torch.rand(batch_size, num_classes, height, width)\n",
    "\n",
    "targets = torch.randint(0, 2, (batch_size, num_classes, height, width)).float()\n",
    "\n",
    "# Initialize Dice Loss\n",
    "dice_loss2 = DiceLoss()\n",
    "\n",
    "# Calculate loss\n",
    "loss = dice_loss2(predictions, targets)\n",
    "\n",
    "print(f'Dice Loss: {loss.item()}')\n",
    "\n",
    "loss = dice_loss(predictions, targets, True)\n",
    "\n",
    "print(f'Dice Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def dice_loss(predictions, labels, include_background = False, apply_softamax = False):\n",
    "    \"\"\"compute dice loss as a mean dice score across all classes\n",
    "\n",
    "    Args:\n",
    "        predictions (tensor(batch, num_clases, height, width)): predictions from segmentation models 0 to 1 probabilites for class\n",
    "        labels (tensor(batch, height, width)): labels for each pixel, values = 0...number of classes - 1\n",
    "        include_background (bool, optional): if True include background class. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tensor[1]: loss\n",
    "    \"\"\"\n",
    "\n",
    "    n_classes = predictions.shape[1]\n",
    "    labels_oh = torch.nn.functional.one_hot(labels, num_classes=n_classes).permute((0,3,1,2))\n",
    "    if apply_softamax:\n",
    "        predictions = torch.nn.functional.softmax(predictions, dim = 1)\n",
    "\n",
    "    # if not soft:\n",
    "    #     predictions = torch.argmax(predictions, dim=1)\n",
    "    #     predictions = nn.functional.one_hot(predictions, num_classes = n_classes).permute((0,3,1,2))\n",
    "\n",
    "    if not include_background:\n",
    "        predictions = predictions[:,1:, :, :]\n",
    "        labels_oh = labels_oh[:,1:,:,:]\n",
    "\n",
    "    intersection = torch.sum(predictions * labels_oh, dim=(1,2,3))\n",
    "    union = torch.sum(predictions, dim=(1,2,3)) + torch.sum(labels_oh, dim=(1,2,3))\n",
    "    dice_score = (2.0 * intersection) / (union)  # Adding a small epsilon to avoid division by zero\n",
    "    return 1 - torch.mean(dice_score, dim=0)\n",
    "\n",
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, smooth=0):#1e-5):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        predictions = torch.softmax(predictions, dim=1)\n",
    "        predictions = predictions.contiguous().view(predictions.shape[0], predictions.shape[1], -1)\n",
    "        targets = targets.contiguous().view(targets.shape[0], targets.shape[1], -1)\n",
    "\n",
    "        intersection = (predictions * targets).sum(2)\n",
    "        denominator = predictions.sum(2) + targets.sum(2)\n",
    "\n",
    "        dice = (2. * intersection + self.smooth) / (denominator + self.smooth)\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "# Simulate predictions and targets\n",
    "batch_size, num_classes, height, width = 4, 3, 256, 256  # Example dimensions\n",
    "\n",
    "# Random predictions\n",
    "predictions = torch.rand(batch_size, num_classes, height, width)\n",
    "\n",
    "# Random targets with class numbers\n",
    "target_classes = torch.randint(0, num_classes, (batch_size, height, width))\n",
    "\n",
    "# Convert targets to one-hot encoding\n",
    "targets_one_hot = F.one_hot(target_classes, num_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "# Initialize Dice Loss\n",
    "dice_loss2 = DiceLoss()\n",
    "\n",
    "# Calculate loss\n",
    "loss = dice_loss2(predictions, targets_one_hot)\n",
    "# print(predictions)\n",
    "# print(target_classes)\n",
    "print(f'Dice Loss: {loss.item()}')\n",
    "# Calculate loss\n",
    "loss = dice_loss(predictions, target_classes, include_background=True, apply_softamax=True)\n",
    "\n",
    "print(f'Dice Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
