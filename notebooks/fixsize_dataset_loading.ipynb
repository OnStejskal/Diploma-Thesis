{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.io.image import read_image,ImageReadMode\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "import torchvision.transforms.functional as F\n",
    "import os\n",
    "import torchvision.transforms as T\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_dataset_dir = os.path.join(\"data\", \"new_segmentation_data\")\n",
    "class ExpertSegmentationDataset(Dataset):\n",
    "  \"\"\" reads dataset from `segm_dataset_dir`, providing pairs \n",
    "   (grayscale img 1xWxH, image of target indices WxH) \"\"\"\n",
    "\n",
    "  mapping=torch.tensor([ (0,0,0),(255,0,0),(0,255,0),(0,0,255) ],dtype=torch.uint8)\n",
    "  # encoding: 0 (black)=background,  1 (red)=wall, 2 (green)=plaque, 3 (blue)=lumen\n",
    "  missing=255\n",
    "\n",
    "  @classmethod\n",
    "  def rgb_to_index(cls,seg):\n",
    "    #print(f\"rgb_to_index {seg.shape}\")\n",
    "    assert(seg.shape[0]==3) \n",
    "    #print(\"rgb_to_index \",torch.unique(torch.reshape(seg,(3,-1)),dim=1))  \n",
    "    c=cls.missing*torch.ones(seg.shape[1:],dtype=torch.uint8)\n",
    "    for k in range(cls.mapping.shape[0]): # go over all classes\n",
    "        mask=(seg==cls.mapping[k,:].unsqueeze(1).unsqueeze(2)).all(0) # binary mask\n",
    "        c[mask]=k  \n",
    "    assert((c!=cls.missing).all())\n",
    "    return c.unsqueeze(0)\n",
    "\n",
    "  @classmethod\n",
    "  def inds2rgb(cls,inds):\n",
    "    y=torch.zeros((3,inds.shape[0],inds.shape[1]),dtype=torch.uint8)\n",
    "    for k in range(cls.mapping.shape[0]):\n",
    "        y[:,(inds==k).squeeze(0)]=cls.mapping[k,:].unsqueeze(1)\n",
    "    return y\n",
    "\n",
    "\n",
    "  @classmethod\n",
    "  def crop(self,img):\n",
    "    return F.crop(img,120,185,595,645) \n",
    "\n",
    "\n",
    "  def __init__(self,names,atransform=None,crop=True):\n",
    "    \"\"\" `names` is a list of filenames, `atransform` is an albumentation transform \"\"\"\n",
    "    super().__init__()\n",
    "    self.names=names\n",
    "    self.atransform=atransform\n",
    "    self.do_crop=crop\n",
    "\n",
    "  def  __getitem__(self,index):\n",
    "    filename=self.names[index]\n",
    "    #print(f\"SegmentationDataset reading file {filename}\")\n",
    "    img=read_image(os.path.join(segm_dataset_dir,'data/trans',filename),ImageReadMode.GRAY)\n",
    "    if self.do_crop:\n",
    "       img=self.crop(img)\n",
    "    seg=read_image(os.path.join(segm_dataset_dir,'references/trans',filename),ImageReadMode.RGB)\n",
    "    if self.do_crop:\n",
    "       seg=self.crop(seg)\n",
    "    inds=self.rgb_to_index(seg)\n",
    "    #print(f\"inds.shape={inds.shape} {inds.dtype}\")\n",
    "    assert(img.shape[0]==1)\n",
    "    assert(inds.shape[0]==1)\n",
    "    if self.atransform:\n",
    "        # tranform image and segmentation together\n",
    "        transformed=self.atransform(image=img[0].numpy(),mask=inds[0].numpy())\n",
    "        img=T.ToTensor()(transformed['image'])\n",
    "        inds=torch.as_tensor(transformed['mask'])\n",
    "        \n",
    "    #print(f\"transformed inds.shape={inds.shape} {inds.dtype}\")\n",
    "    assert(type(img)==torch.Tensor)    \n",
    "    return (img,inds)\n",
    "\n",
    "  def __len__(self):\n",
    "         return len(self.names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation.common.visualization import plot_image_label\n",
    "atransformations_test=A.Compose([\n",
    "     A.CenterCrop(512,512)\n",
    "     ])\n",
    "\n",
    "ds = ExpertSegmentationDataset(names = [\"p_201501061025140196VAS.png\"], atransform=atransformations_test )\n",
    "\n",
    "img, label = ds[0]\n",
    "plot_image_label(img, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
